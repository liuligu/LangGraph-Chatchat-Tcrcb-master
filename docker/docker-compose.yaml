version: '3.9'
services:
  xinference:
    # 阿里云
    image: registry.cn-beijing.aliyuncs.com/chatchat/xinference:qwen2.5-2024-1117
    # DockerHub
    # image: chatchatspace/xinference:qwen2.5-2024-1117
    restart: no # 异常退出后需要手动拉起, 并进入容器内启动模型, 命令见 README_docker_install.md
    command: xinference-local -H 0.0.0.0
    ports:
      - "9997:9997"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia
    # 模型源更改为 ModelScope, 注释掉即为 HuggingFace
    environment:
      - XINFERENCE_MODEL_SRC=modelscope
  chatchat:
    image: ccr.ccs.tencentyun.com/langgraph-chatchat/langgraph-chatchat:v0.0.1-1118
    restart: always
    ports:
      - "80:8501"
    depends_on: # 可选
      - xinference
    # 知识库和配置文件挂载
    # 1. 将 LangGraph-Chatchat/docker/chatchat_data.tar.gz 下载到本地并解压, 比如说解压缩后目录为 /root/chatchat_data
    # 2. 将本地路径(/root/chatchat_data)挂载到容器默认数据路径($CHATCHAT_ROOT)中
    volumes:
      - /root/chatchat_data:/root/chatchat_data