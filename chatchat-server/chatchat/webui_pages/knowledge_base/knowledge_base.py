import time
import pandas as pd
from st_aggrid import AgGrid, JsCode
from st_aggrid.grid_options_builder import GridOptionsBuilder

from chatchat.server.knowledge_base.kb_service.base import (
    get_kb_details,
    get_kb_file_details,
)
from chatchat.server.knowledge_base.utils import LOADER_DICT, get_file_path

from chatchat.webui_pages.utils import *

cell_renderer = JsCode(
    """function(params) {if(params.value==true){return 'âœ“'}else{return 'Ã—'}}"""
)

# å®šä¹‰æ–‡æœ¬åˆ†å‰²å™¨å­—å…¸
Splitters_Dict = {
    "æ ¹æ®æ–‡æœ¬é•¿åº¦åˆ†å‰²": "ChineseRecursiveTextSplitter",
    "ä¸éœ€è¦åˆ†å‰²": "NoneTextSplitter",
}


def config_aggrid(
    df: pd.DataFrame,
    columns: Dict[Tuple[str, str], Dict] = {},
    selection_mode: Literal["single", "multiple", "disabled"] = "single",
    use_checkbox: bool = False,
) -> GridOptionsBuilder:
    gb = GridOptionsBuilder.from_dataframe(df)
    gb.configure_column("No", width=40)
    for (col, header), kw in columns.items():
        gb.configure_column(col, header, wrapHeaderText=True, **kw)
    gb.configure_selection(
        selection_mode=selection_mode,
        use_checkbox=use_checkbox,
        pre_selected_rows=st.session_state.get("selected_rows", [0]),
    )
    gb.configure_pagination(
        enabled=True, paginationAutoPageSize=False, paginationPageSize=10
    )
    return gb


def file_exists(kb: str, selected_rows: List) -> Tuple[str, str]:
    """
    check whether a doc file exists in local knowledge base folder.
    return the file's name and path if it exists.
    """
    if selected_rows:
        file_name = selected_rows[0]["file_name"]
        file_path = get_file_path(kb, file_name)
        if os.path.isfile(file_path):
            return file_name, file_path
    return "", ""


def knowledge_base_page(api: ApiRequest, is_lite: bool = None):
    st.title(" ğŸ“– çŸ¥è¯†åº“ç®¡ç†")
    try:
        kb_list = {x["kb_name"]: x for x in get_kb_details()}
    except Exception as e:
        st.error(
            "è·å–çŸ¥è¯†åº“ä¿¡æ¯é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å·²æŒ‰ç…§ `README.md` ä¸­ `4 çŸ¥è¯†åº“åˆå§‹åŒ–ä¸è¿ç§»` æ­¥éª¤å®Œæˆåˆå§‹åŒ–æˆ–è¿ç§»ï¼Œæˆ–æ˜¯å¦ä¸ºæ•°æ®åº“è¿æ¥é”™è¯¯ã€‚"
        )
        st.stop()
    kb_names = list(kb_list.keys())

    if (
        "selected_kb_name" in st.session_state
        and st.session_state["selected_kb_name"] in kb_names
    ):
        selected_kb_index = kb_names.index(st.session_state["selected_kb_name"])
    else:
        selected_kb_index = 0

    if "selected_kb_info" not in st.session_state:
        st.session_state["selected_kb_info"] = ""

    def format_selected_kb(kb_name: str) -> str:
        if kb := kb_list.get(kb_name):
            return f"{kb_name} ({kb['vs_type']} @ {kb['embed_model']})"
        else:
            return kb_name

    selected_kb = st.selectbox(
        "è¯·é€‰æ‹©æˆ–æ–°å»ºçŸ¥è¯†åº“:",
        kb_names + ["æ–°å»ºçŸ¥è¯†åº“"],
        format_func=format_selected_kb,
        index=selected_kb_index,
    )

    if selected_kb == "æ–°å»ºçŸ¥è¯†åº“":
        with st.form("æ–°å»ºçŸ¥è¯†åº“"):
            kb_name = st.text_input(
                "æ–°å»ºçŸ¥è¯†åº“åç§°",
                placeholder="æ–°çŸ¥è¯†åº“åç§°ï¼Œä¸æ”¯æŒä¸­æ–‡å‘½å",
                key="kb_name",
            )
            kb_info = st.text_input(
                "çŸ¥è¯†åº“ç®€ä»‹",
                placeholder="çŸ¥è¯†åº“ç®€ä»‹ï¼Œæ–¹ä¾¿AgentæŸ¥æ‰¾",
                key="kb_info",
            )

            col0, _ = st.columns([3, 1])

            vs_types = list(Settings.kb_settings.kbs_config.keys())
            vs_type = col0.selectbox(
                "å‘é‡åº“ç±»å‹",
                vs_types,
                index=vs_types.index(Settings.kb_settings.DEFAULT_VS_TYPE),
                key="vs_type",
            )

            col1, _ = st.columns([3, 1])
            with col1:
                embed_models = list(get_config_models(model_type="embed"))
                index = 0
                if get_default_embedding() in embed_models:
                    index = embed_models.index(get_default_embedding())
                embed_model = st.selectbox("Embeddingsæ¨¡å‹", embed_models, index)

            submit_create_kb = st.form_submit_button(
                "æ–°å»º",
                # disabled=not bool(kb_name),
                use_container_width=True,
            )

        if submit_create_kb:
            if not kb_name or not kb_name.strip():
                st.error(f"çŸ¥è¯†åº“åç§°ä¸èƒ½ä¸ºç©ºï¼")
            elif kb_name in kb_list:
                st.error(f"åä¸º {kb_name} çš„çŸ¥è¯†åº“å·²ç»å­˜åœ¨ï¼")
            elif embed_model is None:
                st.error(f"è¯·é€‰æ‹©Embeddingæ¨¡å‹ï¼")
            else:
                ret = api.create_knowledge_base(
                    knowledge_base_name=kb_name,
                    vector_store_type=vs_type,
                    embed_model=embed_model,
                )
                st.toast(ret.get("msg", " "))
                st.session_state["selected_kb_name"] = kb_name
                st.session_state["selected_kb_info"] = kb_info
                st.rerun()

    elif selected_kb:
        kb = selected_kb
        st.session_state["selected_kb_info"] = kb_list[kb]["kb_info"]
        # ä¸Šä¼ æ–‡ä»¶
        files = st.file_uploader(
            "ä¸Šä¼ çŸ¥è¯†æ–‡ä»¶:",
            [i for ls in LOADER_DICT.values() for i in ls],
            accept_multiple_files=True,
        )
        kb_info = st.text_area(
            "è¯·è¾“å…¥çŸ¥è¯†åº“ä»‹ç»:",
            value=st.session_state["selected_kb_info"],
            max_chars=None,
            key=None,
            help=None,
            on_change=None,
            args=None,
            kwargs=None,
        )

        if kb_info != st.session_state["selected_kb_info"]:
            st.session_state["selected_kb_info"] = kb_info
            api.update_kb_info(kb, kb_info)

        with st.expander("æ–‡ä»¶å¤„ç†é…ç½®", expanded=True):
            cols = st.columns(3)

            # é€‰æ‹©å¤„ç†æ–¹å¼
            cols[0].selectbox(
                "é€‰æ‹©å¤„ç†æ–¹å¼ï¼š",
                options=list(Splitters_Dict.keys()),
                key="selected_splitter_key"
            )

            # è·å–é€‰ä¸­çš„åˆ†å‰²å™¨çš„å€¼
            selected_splitter_value = Splitters_Dict[st.session_state["selected_splitter_key"]]
            st.session_state["selected_splitter"] = selected_splitter_value  # æ›´æ–° session_state

            # å¦‚æœé€‰æ‹©äº†æ ¹æ®æ–‡æœ¬é•¿åº¦åˆ†å‰²ï¼Œæ˜¾ç¤ºç›¸å…³è®¾ç½®
            if st.session_state["selected_splitter"] == "ChineseRecursiveTextSplitter":
                chunk_size = cols[1].number_input("å•æ®µæ–‡æœ¬æœ€å¤§é•¿åº¦:", 1, 32768, Settings.kb_settings.CHUNK_SIZE)
                chunk_overlap = cols[2].number_input(
                    "ç›¸é‚»æ–‡æœ¬é‡åˆé•¿åº¦:", 0, chunk_size, Settings.kb_settings.OVERLAP_SIZE
                )
            elif st.session_state["selected_splitter"] == "NoneTextSplitter":
                chunk_size, chunk_overlap = None, None
                st.info("ä¸å¯¹æ–‡ä»¶è¿›è¡Œåˆ†å‰²å¤„ç†ï¼Œç›´æ¥ä¸Šä¼ åˆ°çŸ¥è¯†åº“ä¸­ã€‚", icon="â„¹ï¸")

            # å…¶ä»–è®¾ç½®
            cols[0].write("")
            cols[0].write("")
            zh_title_enhance = cols[0].checkbox("å¼€å¯ä¸­æ–‡æ ‡é¢˜åŠ å¼º", Settings.kb_settings.ZH_TITLE_ENHANCE)

        if st.button(
            "æ·»åŠ æ–‡ä»¶åˆ°çŸ¥è¯†åº“",
            # use_container_width=True,
            disabled=len(files) == 0,
        ):
            ret = api.upload_kb_docs(
                files,
                knowledge_base_name=kb,
                override=True,
                text_splitter_name=st.session_state["selected_splitter"],
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                zh_title_enhance=zh_title_enhance,
            )
            if msg := check_success_msg(ret):
                st.toast(msg, icon="âœ”")
            elif msg := check_error_msg(ret):
                st.toast(msg, icon="âœ–")

        st.divider()

        # çŸ¥è¯†åº“è¯¦æƒ…
        # st.info("è¯·é€‰æ‹©æ–‡ä»¶ï¼Œç‚¹å‡»æŒ‰é’®è¿›è¡Œæ“ä½œã€‚")
        doc_details = pd.DataFrame(get_kb_file_details(kb))
        selected_rows = []
        if not len(doc_details):
            st.info(f"çŸ¥è¯†åº“ `{kb}` ä¸­æš‚æ— æ–‡ä»¶")
        else:
            st.write(f"çŸ¥è¯†åº“ `{kb}` ä¸­å·²æœ‰æ–‡ä»¶:")
            st.info("çŸ¥è¯†åº“ä¸­åŒ…å«æºæ–‡ä»¶ä¸å‘é‡åº“ï¼Œè¯·ä»ä¸‹è¡¨ä¸­é€‰æ‹©æ–‡ä»¶åæ“ä½œ")
            doc_details.drop(columns=["kb_name"], inplace=True)
            doc_details = doc_details[
                [
                    "No",
                    "file_name",
                    "document_loader",
                    "text_splitter",
                    "docs_count",
                    "in_folder",
                    "in_db",
                ]
            ]
            doc_details["in_folder"] = (
                doc_details["in_folder"].replace(True, "âœ“").replace(False, "Ã—")
            )
            doc_details["in_db"] = (
                doc_details["in_db"].replace(True, "âœ“").replace(False, "Ã—")
            )
            gb = config_aggrid(
                doc_details,
                {
                    ("No", "åºå·"): {},
                    ("file_name", "æ–‡æ¡£åç§°"): {},
                    # ("file_ext", "æ–‡æ¡£ç±»å‹"): {},
                    # ("file_version", "æ–‡æ¡£ç‰ˆæœ¬"): {},
                    ("document_loader", "æ–‡æ¡£åŠ è½½å™¨"): {},
                    ("docs_count", "æ–‡æ¡£æ•°é‡"): {},
                    ("text_splitter", "åˆ†è¯å™¨"): {},
                    # ("create_time", "åˆ›å»ºæ—¶é—´"): {},
                    ("in_folder", "æºæ–‡ä»¶"): {},
                    ("in_db", "å‘é‡åº“"): {},
                },
                "multiple",
            )

            doc_grid = AgGrid(
                doc_details,
                gb.build(),
                columns_auto_size_mode="FIT_CONTENTS",
                theme="alpine",
                custom_css={
                    "#gridToolBar": {"display": "none"},
                },
                allow_unsafe_jscode=True,
                enable_enterprise_modules=False,
            )

            selected_rows = doc_grid.get("selected_rows")
            if selected_rows is None:
                selected_rows = []
            else:
                selected_rows = selected_rows.to_dict("records")
            cols = st.columns(4)
            file_name, file_path = file_exists(kb, selected_rows)
            if file_path:
                with open(file_path, "rb") as fp:
                    cols[0].download_button(
                        "ä¸‹è½½é€‰ä¸­æ–‡æ¡£",
                        fp,
                        file_name=file_name,
                        use_container_width=True,
                    )
            else:
                cols[0].download_button(
                    "ä¸‹è½½é€‰ä¸­æ–‡æ¡£",
                    "",
                    disabled=True,
                    use_container_width=True,
                )

            st.write()
            # å°†æ–‡ä»¶åˆ†è¯å¹¶åŠ è½½åˆ°å‘é‡åº“ä¸­
            if cols[1].button(
                "é‡æ–°æ·»åŠ è‡³å‘é‡åº“"
                if selected_rows and (pd.DataFrame(selected_rows)["in_db"]).any()
                else "æ·»åŠ è‡³å‘é‡åº“",
                disabled=not file_exists(kb, selected_rows)[0],
                use_container_width=True,
            ):
                file_names = [row["file_name"] for row in selected_rows]
                api.update_kb_docs(
                    kb,
                    file_names=file_names,
                    text_splitter_name=st.session_state["selected_splitter"],
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap,
                    zh_title_enhance=zh_title_enhance,
                )
                st.rerun()

            # å°†æ–‡ä»¶ä»å‘é‡åº“ä¸­åˆ é™¤ï¼Œä½†ä¸åˆ é™¤æ–‡ä»¶æœ¬èº«ã€‚
            if cols[2].button(
                "ä»å‘é‡åº“åˆ é™¤",
                disabled=not (selected_rows and selected_rows[0]["in_db"]),
                use_container_width=True,
            ):
                file_names = [row["file_name"] for row in selected_rows]
                api.delete_kb_docs(kb, file_names=file_names)
                st.rerun()

            if cols[3].button(
                "ä»çŸ¥è¯†åº“ä¸­åˆ é™¤",
                type="primary",
                use_container_width=True,
            ):
                file_names = [row["file_name"] for row in selected_rows]
                api.delete_kb_docs(kb, file_names=file_names, delete_content=True)
                st.rerun()

        st.divider()

        cols = st.columns(3)

        if cols[0].button(
            "ä¾æ®æºæ–‡ä»¶é‡å»ºå‘é‡åº“",
            help="æ— éœ€ä¸Šä¼ æ–‡ä»¶ï¼Œé€šè¿‡å…¶å®ƒæ–¹å¼å°†æ–‡æ¡£æ‹·è´åˆ°å¯¹åº”çŸ¥è¯†åº“contentç›®å½•ä¸‹ï¼Œç‚¹å‡»æœ¬æŒ‰é’®å³å¯é‡å»ºçŸ¥è¯†åº“ã€‚",
            use_container_width=True,
            type="primary",
        ):
            with st.spinner("å‘é‡åº“é‡æ„ä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼Œå‹¿åˆ·æ–°æˆ–å…³é—­é¡µé¢ã€‚"):
                empty = st.empty()
                empty.progress(0.0, "")
                for d in api.recreate_vector_store(
                    kb,
                    text_splitter_name=st.session_state["selected_splitter"],
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap,
                    zh_title_enhance=zh_title_enhance,
                ):
                    if msg := check_error_msg(d):
                        st.toast(msg)
                    else:
                        empty.progress(d["finished"] / d["total"], d["msg"])
                st.rerun()

        if cols[2].button(
            "åˆ é™¤çŸ¥è¯†åº“",
            use_container_width=True,
        ):
            ret = api.delete_knowledge_base(kb)
            st.toast(ret.get("msg", " "))
            time.sleep(1)
            st.rerun()

        with st.sidebar:
            keyword = st.text_input("æŸ¥è¯¢å…³é”®å­—")
            top_k = st.slider("åŒ¹é…æ¡æ•°", 1, 100, 3)

        st.write("æ–‡ä»¶å†…æ–‡æ¡£åˆ—è¡¨ã€‚åŒå‡»è¿›è¡Œä¿®æ”¹ï¼Œåœ¨åˆ é™¤åˆ—å¡«å…¥ Y å¯åˆ é™¤å¯¹åº”è¡Œã€‚")
        docs = []
        df = pd.DataFrame([], columns=["seq", "id", "content", "source"])
        if selected_rows:
            file_name = selected_rows[0]["file_name"]
            docs = api.search_kb_docs(
                knowledge_base_name=selected_kb, file_name=file_name
            )

            data = [
                {
                    "seq": i + 1,
                    "id": x["id"],
                    "page_content": x["page_content"],
                    "source": x["metadata"].get("source"),
                    "type": x["type"],
                    "metadata": json.dumps(x["metadata"], ensure_ascii=False),
                    "to_del": "",
                }
                for i, x in enumerate(docs)
            ]
            df = pd.DataFrame(data)

            gb = GridOptionsBuilder.from_dataframe(df)
            gb.configure_columns(["id", "source", "type", "metadata"], hide=True)
            gb.configure_column("seq", "No.", width=50)
            gb.configure_column(
                "page_content",
                "å†…å®¹",
                editable=True,
                autoHeight=True,
                wrapText=True,
                flex=1,
                cellEditor="agLargeTextCellEditor",
                cellEditorPopup=True,
            )
            gb.configure_column(
                "to_del",
                "åˆ é™¤",
                editable=True,
                width=50,
                wrapHeaderText=True,
                cellEditor="agCheckboxCellEditor",
                cellRender="agCheckboxCellRenderer",
            )
            # å¯ç”¨åˆ†é¡µ
            gb.configure_pagination(
                enabled=True, paginationAutoPageSize=False, paginationPageSize=10
            )
            gb.configure_selection()
            edit_docs = AgGrid(df, gb.build(), fit_columns_on_grid_load=True)

            if st.button("ä¿å­˜æ›´æ”¹"):
                origin_docs = {
                    x["id"]: {
                        "page_content": x["page_content"],
                        "type": x["type"],
                        "metadata": x["metadata"],
                    }
                    for x in docs
                }
                changed_docs = []
                for index, row in edit_docs.data.iterrows():
                    origin_doc = origin_docs[row["id"]]
                    if row["page_content"] != origin_doc["page_content"]:
                        if row["to_del"] not in ["Y", "y", 1]:
                            changed_docs.append(
                                {
                                    "page_content": row["page_content"],
                                    "type": row["type"],
                                    "metadata": json.loads(row["metadata"]),
                                }
                            )

                if changed_docs:
                    if api.update_kb_docs(
                        knowledge_base_name=selected_kb,
                        file_names=[file_name],
                        docs={file_name: changed_docs},
                    ):
                        st.toast("æ›´æ–°æ–‡æ¡£æˆåŠŸ")
                    else:
                        st.toast("æ›´æ–°æ–‡æ¡£å¤±è´¥")
